"""
å¤§è§„æ¨¡æ•°æ®ç”Ÿæˆç¤ºä¾‹ - Fin-Data-Maker v2.1.0

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ç”Ÿæˆå’Œå¤„ç†å¤§è§„æ¨¡æ•°æ®ï¼ˆ10ä¸‡+è®°å½•ï¼‰:
1. æ‰¹é‡ç”Ÿæˆç­–ç•¥ - åˆ†æ‰¹ç”Ÿæˆé¿å…å†…å­˜æº¢å‡º
2. æ€§èƒ½ä¼˜åŒ– - å…³é—­å®æ—¶éªŒè¯æå‡é€Ÿåº¦
3. è¿›åº¦ç›‘æ§ - å®æ—¶æ˜¾ç¤ºå¤§æ•°æ®ç”Ÿæˆè¿›åº¦
4. å¢é‡å¯¼å‡º - è¾¹ç”Ÿæˆè¾¹å¯¼å‡ºå‡å°‘å†…å­˜å ç”¨
5. æ€§èƒ½ç»Ÿè®¡ - è®°å½•ç”Ÿæˆé€Ÿåº¦å’Œèµ„æºä½¿ç”¨

é€‚ç”¨åœºæ™¯:
- æ€§èƒ½æµ‹è¯•æ•°æ®å‡†å¤‡
- å¤§è§„æ¨¡æ•°æ®åº“å¡«å……
- å‹åŠ›æµ‹è¯•æ•°æ®é›†
- æ•°æ®è¿ç§»æ¨¡æ‹Ÿ
"""

import sys
import os
import time
import psutil
from datetime import datetime

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.core.app import DataMakerApp
from src.financial.schemas import (
    create_customer_table,
    create_account_table,
    create_transaction_table,
)
from src.analysis.dependency_analyzer import DependencyAnalyzer
from src.core.progress_monitor import ProgressMonitor, ProgressEventType


class PerformanceTracker:
    """æ€§èƒ½è·Ÿè¸ªå™¨"""

    def __init__(self):
        self.start_time = None
        self.metrics = []
        self.process = psutil.Process()

    def start(self):
        """å¼€å§‹è·Ÿè¸ª"""
        self.start_time = time.time()
        self.metrics = []

    def record(self, table_name, record_count):
        """è®°å½•ç”ŸæˆæŒ‡æ ‡"""
        elapsed = time.time() - self.start_time
        memory_mb = self.process.memory_info().rss / 1024 / 1024
        cpu_percent = self.process.cpu_percent()

        self.metrics.append({
            'table': table_name,
            'records': record_count,
            'elapsed': elapsed,
            'memory_mb': memory_mb,
            'cpu_percent': cpu_percent,
            'records_per_sec': record_count / elapsed if elapsed > 0 else 0
        })

    def get_summary(self):
        """è·å–æ€§èƒ½æ‘˜è¦"""
        if not self.metrics:
            return "æ— æ•°æ®"

        total_records = sum(m['records'] for m in self.metrics)
        total_time = time.time() - self.start_time
        avg_speed = total_records / total_time if total_time > 0 else 0
        max_memory = max(m['memory_mb'] for m in self.metrics)

        return f"""
æ€§èƒ½ç»Ÿè®¡:
  - æ€»è®°å½•æ•°: {total_records:,}
  - æ€»ç”¨æ—¶: {total_time:.2f} ç§’
  - å¹³å‡é€Ÿåº¦: {avg_speed:.0f} æ¡/ç§’
  - å³°å€¼å†…å­˜: {max_memory:.1f} MB
"""


def large_scale_generation_demo():
    """å¤§è§„æ¨¡æ•°æ®ç”Ÿæˆæ¼”ç¤º"""

    print("=" * 80)
    print("  ğŸš€ å¤§è§„æ¨¡æ•°æ®ç”Ÿæˆç¤ºä¾‹")
    print("=" * 80)

    # é…ç½®
    config = {
        'customer': {'total': 100000, 'batch': 5000},    # 10ä¸‡å®¢æˆ·
        'account': {'total': 200000, 'batch': 10000},    # 20ä¸‡è´¦æˆ·
        'transaction': {'total': 500000, 'batch': 50000} # 50ä¸‡äº¤æ˜“
    }

    print("\nç”Ÿæˆè®¡åˆ’:")
    for table, conf in config.items():
        print(f"  {table:15s}: {conf['total']:7,} æ¡ (æ‰¹å¤§å°: {conf['batch']:,})")

    total_records = sum(c['total'] for c in config.values())
    print(f"\n  æ€»è®¡: {total_records:,} æ¡è®°å½•")

    # ä¼°ç®—æ—¶é—´ï¼ˆåŸºäºç»éªŒå€¼ï¼šçº¦1000æ¡/ç§’ï¼‰
    estimated_time = total_records / 1000
    print(f"  é¢„è®¡è€—æ—¶: {estimated_time:.0f} ç§’ ({estimated_time/60:.1f} åˆ†é’Ÿ)")

    print("\næŒ‰Enteré”®å¼€å§‹ç”Ÿæˆ...")
    input()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "output/large_scale"
    os.makedirs(output_dir, exist_ok=True)

    # ============================================================
    # å‡†å¤‡ç¯å¢ƒ
    # ============================================================
    print("\n" + "=" * 80)
    print("  å‡†å¤‡ç”Ÿæˆç¯å¢ƒ")
    print("=" * 80)

    # åˆ›å»ºè¡¨å®šä¹‰
    tables = [
        create_customer_table(),
        create_account_table(),
        create_transaction_table(),
    ]

    # åˆ†æä¾èµ–å…³ç³»
    analyzer = DependencyAnalyzer(tables)
    generation_order = analyzer.get_generation_order()
    print(f"\nâœ“ ç”Ÿæˆé¡ºåº: {' â†’ '.join(generation_order)}")

    # åˆ›å»ºåº”ç”¨
    app = DataMakerApp(seed=None)  # ä¸ä½¿ç”¨å›ºå®šç§å­ï¼Œç”Ÿæˆéšæœºæ•°æ®
    for table in tables:
        app.add_table(table)

    # åˆ›å»ºè¿›åº¦ç›‘æ§
    monitor = ProgressMonitor()

    # è¿›åº¦æ¡å›è°ƒ
    def progress_callback(event):
        if event.event_type == ProgressEventType.PROGRESS:
            bar_length = 40
            filled = int(bar_length * event.percentage / 100)
            bar = 'â–ˆ' * filled + '-' * (bar_length - filled)
            eta_str = f"ETA: {event.eta:.0f}s" if event.eta > 0 else ""
            print(f"\r  è¿›åº¦: |{bar}| {event.percentage:5.1f}% | {event.current:,}/{event.total:,} | {eta_str}",
                  end='', flush=True)
        elif event.event_type in (ProgressEventType.TABLE_COMPLETED, ProgressEventType.ERROR):
            print()  # æ¢è¡Œ

    monitor.add_callback(progress_callback)

    # æ€§èƒ½è·Ÿè¸ª
    perf_tracker = PerformanceTracker()
    perf_tracker.start()

    print("âœ“ ç¯å¢ƒå‡†å¤‡å®Œæˆ\n")

    # ============================================================
    # ç”Ÿæˆæ•°æ®
    # ============================================================
    print("=" * 80)
    print("  å¼€å§‹ç”Ÿæˆæ•°æ®")
    print("=" * 80)

    generated_ids = {}  # å­˜å‚¨ç”Ÿæˆçš„IDä¾›åç»­å¼•ç”¨

    for table_name in generation_order:
        if table_name not in config:
            continue

        total_count = config[table_name]['total']
        batch_size = config[table_name]['batch']

        print(f"\nã€{table_name}ã€‘- æ€»è®¡ {total_count:,} æ¡ï¼Œæ‰¹å¤§å° {batch_size:,}")

        monitor.table_started(table_name, total_count)

        # å‡†å¤‡å…³è”æ•°æ®
        related_data = None
        dependencies = analyzer.graph.get_dependencies(table_name)
        if dependencies:
            related_data = {}
            for dep in dependencies:
                if dep in generated_ids:
                    related_data[dep] = generated_ids[dep]
            print(f"  ä¾èµ–: {', '.join(dependencies)}")

        # åˆ†æ‰¹ç”Ÿæˆ
        all_ids = []
        batch_num = 0

        for start_idx in range(0, total_count, batch_size):
            batch_num += 1
            current_batch_size = min(batch_size, total_count - start_idx)

            # ç”Ÿæˆæ•°æ®ï¼ˆä¸éªŒè¯ä»¥æé«˜é€Ÿåº¦ï¼‰
            if related_data:
                batch_data, _ = app.generate_with_relations(
                    table_name,
                    count=current_batch_size,
                    related_data=related_data,
                    validate=False
                )
            else:
                batch_data, _ = app.generate_data(
                    table_name,
                    count=current_batch_size,
                    validate=False
                )

            # æå–ID
            id_field = f"{table_name}_id"
            batch_ids = [item[id_field] for item in batch_data if id_field in item]
            all_ids.extend(batch_ids)

            # å¢é‡å¯¼å‡ºï¼ˆè¾¹ç”Ÿæˆè¾¹å†™å…¥ï¼Œå‡å°‘å†…å­˜å ç”¨ï¼‰
            csv_file = f"{output_dir}/{table_name}.csv"
            app.export_to_csv(
                batch_data,
                table_name,
                csv_file,
                mode='a' if batch_num > 1 else 'w'  # è¿½åŠ æ¨¡å¼
            )

            # æ›´æ–°è¿›åº¦
            completed = start_idx + current_batch_size
            monitor.update(completed, f"æ‰¹æ¬¡ #{batch_num}")

        # å­˜å‚¨IDä¾›åç»­ä½¿ç”¨
        generated_ids[table_name] = all_ids

        monitor.table_completed(table_name, total_count)
        perf_tracker.record(table_name, total_count)

        # æ˜¾ç¤ºæ‰¹æ¬¡å®ŒæˆçŠ¶æ€
        print(f"  âœ“ å®Œæˆ {batch_num} ä¸ªæ‰¹æ¬¡ï¼Œå…± {total_count:,} æ¡è®°å½•")
        print(f"  âœ“ å·²å¯¼å‡ºåˆ°: {csv_file}")

    monitor.complete("å¤§è§„æ¨¡æ•°æ®ç”Ÿæˆå®Œæˆï¼")

    # ============================================================
    # æ€§èƒ½æŠ¥å‘Š
    # ============================================================
    print("\n" + "=" * 80)
    print("  ğŸ“Š æ€§èƒ½æŠ¥å‘Š")
    print("=" * 80)

    print(perf_tracker.get_summary())

    # è¯¦ç»†æŒ‡æ ‡
    print("è¯¦ç»†æŒ‡æ ‡:")
    print(f"  {'è¡¨å':<15s} | {'è®°å½•æ•°':>10s} | {'ç”¨æ—¶(ç§’)':>10s} | {'é€Ÿåº¦(æ¡/ç§’)':>12s} | {'å†…å­˜(MB)':>10s}")
    print("  " + "-" * 72)

    for metric in perf_tracker.metrics:
        print(f"  {metric['table']:<15s} | {metric['records']:>10,} | "
              f"{metric['elapsed']:>10.1f} | {metric['records_per_sec']:>12.0f} | "
              f"{metric['memory_mb']:>10.1f}")

    # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šæ–‡ä»¶
    perf_file = f"{output_dir}/performance_report.txt"
    with open(perf_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("å¤§è§„æ¨¡æ•°æ®ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")

        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(perf_tracker.get_summary())

        f.write("\nè¯¦ç»†æŒ‡æ ‡:\n")
        f.write("-" * 80 + "\n")
        for metric in perf_tracker.metrics:
            f.write(f"{metric['table']:15s} | "
                   f"{metric['records']:10,} æ¡ | "
                   f"{metric['elapsed']:8.1f} ç§’ | "
                   f"{metric['records_per_sec']:10.0f} æ¡/ç§’ | "
                   f"{metric['memory_mb']:8.1f} MB\n")

        f.write("\n" + "=" * 80 + "\n")

    print(f"\nâœ“ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {perf_file}")

    # ============================================================
    # æ•°æ®éªŒè¯é‡‡æ ·
    # ============================================================
    print("\n" + "=" * 80)
    print("  ğŸ” æ•°æ®éªŒè¯ï¼ˆé‡‡æ ·ï¼‰")
    print("=" * 80)

    print("\nç”±äºæ•°æ®é‡è¾ƒå¤§ï¼Œä»…å¯¹éƒ¨åˆ†æ•°æ®è¿›è¡ŒéªŒè¯é‡‡æ ·...\n")

    for table_name in generation_order:
        if table_name not in config:
            continue

        # ç”Ÿæˆå°‘é‡æ•°æ®è¿›è¡ŒéªŒè¯
        print(f"  {table_name}: ", end='')
        sample_data, report = app.generate_data(table_name, count=100, validate=True)

        if report.is_valid:
            print(f"âœ“ éªŒè¯é€šè¿‡ (100æ¡é‡‡æ ·)")
        else:
            print(f"âš ï¸  å‘ç° {len(report.errors)} ä¸ªé—®é¢˜")
            for error in report.errors[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"      - {error}")

    # ============================================================
    # æ€»ç»“
    # ============================================================
    print("\n" + "=" * 80)
    print("  âœ… å¤§è§„æ¨¡æ•°æ®ç”Ÿæˆå®Œæˆï¼")
    print("=" * 80)

    total_generated = sum(config[t]['total'] for t in generation_order if t in config)
    total_time = time.time() - perf_tracker.start_time

    print(f"\nç”Ÿæˆç»Ÿè®¡:")
    print(f"  - æ€»è®°å½•æ•°: {total_generated:,}")
    print(f"  - æ€»ç”¨æ—¶: {total_time:.1f} ç§’ ({total_time/60:.1f} åˆ†é’Ÿ)")
    print(f"  - å¹³å‡é€Ÿåº¦: {total_generated/total_time:.0f} æ¡/ç§’")

    print(f"\nè¾“å‡ºæ–‡ä»¶:")
    for table_name in generation_order:
        if table_name in config:
            csv_file = f"{output_dir}/{table_name}.csv"
            if os.path.exists(csv_file):
                size_mb = os.path.getsize(csv_file) / 1024 / 1024
                print(f"  - {csv_file} ({size_mb:.1f} MB)")

    print(f"\nğŸ’¡ æç¤º:")
    print(f"  - æ‰€æœ‰æ•°æ®é‡‡ç”¨å¢é‡å¯¼å‡ºæ–¹å¼ï¼Œå†…å­˜å ç”¨è¾ƒå°")
    print(f"  - å¯ä»¥ä½¿ç”¨æ•°æ®åº“æ‰¹é‡å¯¼å…¥å·¥å…·å¯¼å…¥CSVæ–‡ä»¶")
    print(f"  - å¯¹äºæ›´å¤§è§„æ¨¡æ•°æ®ï¼Œå»ºè®®è°ƒæ•´æ‰¹æ¬¡å¤§å°")

    print("\n" + monitor.get_summary())


if __name__ == '__main__':
    try:
        large_scale_generation_demo()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
